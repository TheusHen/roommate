import 'package:flutter_test/flutter_test.dart';
import 'package:flutter/material.dart';
import 'package:app/pages/voice_chat.dart';

void main() {
  group('VoiceChatScreen', () {
    testWidgets('should display voice chat interface', (WidgetTester tester) async {
      await tester.pumpWidget(
        MaterialApp(
          home: VoiceChatScreen(),
        ),
      );

      // Verify UI elements are present
      expect(find.text('Voice Chat with Roommate'), findsOneWidget);
      expect(find.byIcon(Icons.mic), findsOneWidget);
      expect(find.byIcon(Icons.send), findsOneWidget);
      expect(find.text('Tap mic to speak'), findsOneWidget);
    });

    testWidgets('should show locale selector with English and Portuguese options', (WidgetTester tester) async {
      await tester.pumpWidget(
        MaterialApp(
          home: VoiceChatScreen(),
        ),
      );

      // Find the locale dropdown
      expect(find.byIcon(Icons.language), findsOneWidget);
      
      // The dropdown should be visible
      expect(find.byType(DropdownButton<String>), findsOneWidget);
    });

    testWidgets('should change listening state when mic button is pressed', (WidgetTester tester) async {
      await tester.pumpWidget(
        MaterialApp(
          home: VoiceChatScreen(),
        ),
      );

      // Initially should show mic icon (not listening)
      expect(find.byIcon(Icons.mic), findsOneWidget);
      expect(find.text('Tap mic to speak'), findsOneWidget);

      // Note: We can't easily test the actual mic functionality without mocking
      // but we can verify the UI structure is correct
    });

    testWidgets('should have send button for transmitting recognized text', (WidgetTester tester) async {
      await tester.pumpWidget(
        MaterialApp(
          home: VoiceChatScreen(),
        ),
      );

      // Verify send button exists
      expect(find.byIcon(Icons.send), findsOneWidget);
      
      // Verify it's in the correct row with mic button
      expect(find.byType(Row), findsWidgets);
    });
  });

  group('Voice Chat Data Flow', () {
    test('should handle text recognition flow', () {
      // This test verifies the expected data flow described in the requirements:
      // üéôÔ∏è microphone ‚Üí vosk_flutter ‚Üí text (_text) ‚Üí send via HTTP ‚Üí response ‚Üí flutter_tts
      
      // 1. Simulated vosk recognition result
      const recognizedText = 'Hello roommate how are you';
      
      // 2. Text should be valid for processing
      expect(recognizedText, isNotEmpty);
      expect(recognizedText, isA<String>());
      expect(recognizedText.trim(), equals('Hello roommate how are you'));
      
      // 3. Text should be ready for HTTP API call
      final apiPayload = {"prompt": "Said: ${recognizedText.trim()}"};
      expect(apiPayload['prompt'], equals('Said: Hello roommate how are you'));
    });

    test('should handle locale-specific model paths', () {
      // Test that correct model paths are used for different locales
      const enUsModelPath = 'assets/models/vosk-model-small-en-us-0.15.zip';
      const ptBrModelPath = 'assets/models/vosk-model-small-pt-0.3.zip';
      
      // Verify model paths follow expected naming convention
      expect(enUsModelPath, contains('en-us'));
      expect(ptBrModelPath, contains('pt'));
      expect(enUsModelPath, endsWith('.zip'));
      expect(ptBrModelPath, endsWith('.zip'));
    });

    test('should handle language switching correctly', () {
      // Test locale values match dropdown options
      const locales = [
        {'label': 'English', 'value': 'en-US'},
        {'label': 'Portugu√™s', 'value': 'pt-BR'},
      ];
      
      expect(locales[0]['value'], equals('en-US'));
      expect(locales[1]['value'], equals('pt-BR'));
      expect(locales.length, equals(2));
    });
  });
}